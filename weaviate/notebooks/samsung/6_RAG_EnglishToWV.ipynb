{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0a7b82-17a4-4d55-b39c-d4175bab40d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install weaviate-client langchain==0.0.245"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ec37e4-4bff-46c3-953d-47b1b03cc253",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# python libraries\n",
    "import ast\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\n",
    "import weaviate\n",
    "\n",
    "# lanagchain libraries\n",
    "import langchain\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms.sagemaker_endpoint import  SagemakerEndpoint, LLMContentHandler\n",
    "from langchain.retrievers.weaviate_hybrid_search import WeaviateHybridSearchRetriever\n",
    "\n",
    "from langsmith import Client\n",
    "\n",
    "ls_client = Client()\n",
    "sm_client = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15cba9d-07fc-4d3b-991f-a23cc6fecd85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker_session.get_caller_identity_arn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5996d65d-5f5f-4efb-93c5-14cd5d27e9bb",
   "metadata": {},
   "source": [
    "<mark>Define the load balancer for the Weaviate instance</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c3cd81-6823-457f-985f-50a31f23a360",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "elb_endpoint = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce15a24-1ac0-46ca-adda-ae98dcc02bb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wv_client = weaviate.Client(url=f\"http://{elb_endpoint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431119b7-e7f3-49e8-b89f-b3ac61268190",
   "metadata": {},
   "source": [
    "<mark>Optional but recommended: provide your langsmith API key</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a72544-400c-4f24-a07a-a617f2cfe3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "langsmith_api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4875996-6246-4e25-9eff-c7b53977d7ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "today = datetime.now().strftime(\"%Y%m%d\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"English Query - {today}\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = langsmith_api_key "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d4f531-5fcb-4654-ade4-2c95768df5e5",
   "metadata": {},
   "source": [
    "<h1>Deploy SageMaker Endpoint</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e179a7b-aff4-4799-a1ae-a4482e5af614",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "    'HF_MODEL_ID':'openchat/opencoderplus',\n",
    "    'SM_NUM_GPUS': json.dumps(8)\n",
    "}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    image_uri=get_huggingface_llm_image_uri(\"huggingface\",version=\"0.8.2\"),\n",
    "    env=hub,\n",
    "    role=role, \n",
    "    transformers_version=\"4.30.1\",\n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.g5.48xlarge',\n",
    "    container_startup_health_check_timeout=300,\n",
    "    wait=True\n",
    ")\n",
    "\n",
    "llm_opencoder_endpoint_name = predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8211baa7-d528-45f5-b161-c899be9d6b7d",
   "metadata": {},
   "source": [
    "<h1>Define Langchain LLM</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c560281a-5c65-448f-955d-14a1eecd955c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# opencoder\n",
    "parameters = {\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.7,\n",
    "    \"temperature\": 0.1,\n",
    "    \"top_k\": 5,\n",
    "    \"return_full_text\": False,\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"repetition_penalty\": 1.03,\n",
    "    \"stop\": [\"<|end_of_turn|>\"]\n",
    "  }\n",
    "  \n",
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs={}) -> bytes:\n",
    "\n",
    "        input_str = json.dumps({\"inputs\": prompt, \"parameters\": parameters, **model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        result = response_json[0][\"generated_text\"]\n",
    "        result = result.split('<|end_of_turn|>')[0]\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "content_handler = ContentHandler()\n",
    "\n",
    "\n",
    "sm_opencoder_llm = SagemakerEndpoint(\n",
    "    endpoint_name=llm_opencoder_endpoint_name,\n",
    "    region_name=region,\n",
    "    model_kwargs=parameters,\n",
    "    content_handler=content_handler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982f4634-1545-4fa0-ba12-d9c7d7c64139",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm_opencoder_llm(\"What day comes after Tuesday?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a3f62d-fe2e-4a1e-afb0-51164ed26793",
   "metadata": {},
   "source": [
    "<h1>Define LLM Chain</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141dfc76-ee05-4dee-b2f9-d74ec7377597",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"You are an assistant who is an expert at translating a question provided by the User into a Weaviate query that can be executed using the Python client.\n",
    "\n",
    "Use the examples below as a guide.  Return ONLY the results of the Weaviate query and do NOT reformat the results. \n",
    "\n",
    "---\n",
    "Example #1\n",
    "User: {question_1}\n",
    "Assistant: \n",
    "```python\n",
    "{query_1}\n",
    "```\n",
    "---\n",
    "\n",
    "---\n",
    "Example #2\n",
    "User: {question_2}\n",
    "Assistant: \n",
    "```python\n",
    "{query_2}\n",
    "```\n",
    "---\n",
    "\n",
    "---\n",
    "Example #3\n",
    "User: {question_3}\n",
    "Assistant: \n",
    "```python\n",
    "{query_3}\n",
    "```\n",
    "---\n",
    "\n",
    "Begin!\n",
    "\n",
    "User: {user_question}\n",
    "Assistant:\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"user_question\",'question_1','query_1','question_2','query_2','question_3','query_3'],\n",
    "    template=template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2836c5a-b254-41c0-856e-78a34063682f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=sm_opencoder_llm, prompt=prompt_template, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dcab4b-773b-4879-abc6-672a182419c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a retriever for the question bank\n",
    "wv_hybrid_retriever = WeaviateHybridSearchRetriever(client=wv_client, index_name=\"Query\", text_key=\"query\", attributes=['question'], k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324196ff-31e9-4421-b04d-e3361b548949",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wv_hybrid_retriever.get_relevant_documents(query=\"Search for devices that do not have a stylus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354830fc-67ae-45c3-aa71-7061a6cf3b90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a search function\n",
    "def query_weaviate(question: str) -> str:\n",
    "    '''\n",
    "    Converts an English request into a Weaviate query and returns the\n",
    "    results of the query to the user.  The input should always be an\n",
    "    English sentence and the output always returns the result of the\n",
    "    Weaviate query in JSON format.\n",
    "    '''\n",
    "    # collect similar queries\n",
    "    question = question.replace('\"','')\n",
    "    results = wv_hybrid_retriever.get_relevant_documents(query=question)\n",
    "\n",
    "\n",
    "    question_1 = results[0].metadata['question']\n",
    "    query_1 = results[0].page_content\n",
    "\n",
    "    question_2 = results[1].metadata['question']\n",
    "    query_2 = results[1].page_content\n",
    "\n",
    "    question_3 = results[2].metadata['question']\n",
    "    query_3 = results[2].page_content\n",
    "\n",
    "    # run the chain\n",
    "    result = llm_chain.run(user_question=question\n",
    "                          ,question_1=question_1\n",
    "                          ,query_1=query_1\n",
    "                          ,question_2=question_2\n",
    "                          ,query_2=query_2\n",
    "                          ,question_3=question_3\n",
    "                          ,query_3=query_3\n",
    "                          )\n",
    "\n",
    "    query = result.split('```python')[1].split('```')[0]\n",
    "\n",
    "    loc = {}\n",
    "    exec(query, globals(), loc)\n",
    "    response = loc['answer']\n",
    "\n",
    "    return response, query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1f7e03-fd54-4924-b03c-d4a15fb68647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#question = \"\"\"Search for devices that discuss durability with a limit of 1.  Return the \"model_names\" and \"key_features\" fields.\"\"\"\n",
    "\n",
    "#question = \"\"\"Search for devices that have a stylus with a limit of 2.  Return the \"model_names\", \"key_features\", and \"stylus\" fields\"\"\"\n",
    "#question = \"\"\"Search for devices that do not have a stylus with a limit of 1.  Return the \"model_names\", and \"document_summary\", and \"stylus\" fields\"\"\"\n",
    "#question = \"\"\"Search for devices that are durable with a limit of 2.  Return the \"model_names\", \"key_features\", and \"stylus\" fields\"\"\"\n",
    "#question = \"\"\"Search for devices that have a front facing camera with a limit of 2.  Return the \"model_names\", \"key_features\", and \"stylus\" fields\"\"\"\n",
    "\n",
    "#question = \"how many manuals are there with a stylus?\"\n",
    "#question = \"how many manuals are there without a stylus?\"\n",
    "#question = \"how many manuals are there?\"\n",
    "#question = \"what is the total number of manuals that have a stylus?\"\n",
    "#question = \"what is the total number of manuals that do not have a stylus?\"\n",
    "\n",
    "\n",
    "#question = \"\"\"Search for devices that have fast charging with a limit of 3.  Return the \"model_names\" and \"key_features\" fields.\"\"\"\n",
    "#question = \"\"\"Search for devices that have fast charging with a limit of 3.  Return the \"document_summary\" field.\"\"\"\n",
    "#question = \"\"\"Search for devices that have fast charging with a limit of 2.  Return the \"model_names\", \"key_features\" and \"document_summary\" fields.\"\"\"\n",
    "#question = \"\"\"Search for devices that are durable with a limit of 1.  Return the \"model_names\" and \"key_features\" fields.\"\"\"\n",
    "#question = \"\"\"Search for devices that have a stylus with a limit of 2.  Return the \"model_names\", \"key_features\", and \"stylus\" fields\"\"\"\n",
    "\n",
    "question = 'Search for devices that are fast charging with a limit of 1.  Return the \"model_names\", \"key_features\", and \"document_summary\" fields'\n",
    "#question = 'Search for devices that are fast charging with a limit of 2.  Return \"model_names\" and \"key_features\"'\n",
    "\n",
    "#question = \"\"\"Search for devices that have a stylus with a limit of 1.  Return the \"model_names\", and \"document_summary\", and \"stylus\" fields\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b26a42-ee20-4952-86ae-b3ded36088bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IMPORTANT! keep in mind there are only 5 manuals uploaded so our result set will be limited\n",
    "langchain.debug=False # toggle for detailed logs\n",
    "response, query = query_weaviate(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd860295-4838-421a-95c0-9018583557f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cb63cf-b897-4fed-bc63-5366bba5ce02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56779ef1-3330-4e26-bba3-a907350d15d4",
   "metadata": {},
   "source": [
    "<h2>Cleanup</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8bbe31-ce08-41e6-83e9-1edb0e47fa8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm_client.delete_endpoint(\n",
    "    EndpointName=llm_opencoder_endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d33afa-217e-48fb-84af-01236d15f097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
